# TENANT NAME is used i.e. as name for the VRF, as prefix in Intersight and so on.
tenant_name: "test01"

# ESXi Host Names - Separated by either FC or iSCSI. If not using the protocol, comment out the list entries.
# These host names and identifiers will be used for NetApp LUN and igroup names and Cisco MDS Device Alias names 
# and zone entries.
# They can also be assigned as UCS Profile names.

fc_esxi_hosts:
  - hostname: "aa02-esxi-1"
    fcp_a_wwpn: "20:00:00:25:b5:a2:0a:00"
    fcp_b_wwpn: "20:00:00:25:b5:a2:0b:00"
    fc_nvme_a_wwpn: "20:00:00:25:b5:a2:0a:01"
    fc_nvme_b_wwpn: "20:00:00:25:b5:a2:0b:01"
    nvme_nqn: "nqn.2014-08.com.cisco.flexpodb4:nvme:aa02-esxi-1"
  - hostname: "aa02-esxi-3"
    fcp_a_wwpn: "20:00:00:25:b5:a2:0a:02"
    fcp_b_wwpn: "20:00:00:25:b5:a2:0b:02"
    fc_nvme_a_wwpn: "20:00:00:25:b5:a2:0a:03"
    fc_nvme_b_wwpn: "20:00:00:25:b5:a2:0b:03"
    nvme_nqn: "nqn.2014-08.com.cisco.flexpodb4:nvme:aa02-esxi-3"
  - hostname: "aa02-esxi-5"
    fcp_a_wwpn: "20:00:00:25:b5:a2:0a:05"
    fcp_b_wwpn: "20:00:00:25:b5:a2:0b:04"
    fc_nvme_a_wwpn: "20:00:00:25:b5:a2:0a:04"
    fc_nvme_b_wwpn: "20:00:00:25:b5:a2:0b:05"
    nvme_nqn: "nqn.2014-08.com.cisco.flexpodb4:nvme:aa02-esxi-5"

iscsi_esxi_hosts:
  - hostname: "aa02-esxi-2"
    iscsi_iqn: "iqn.2010-11.com.flexpod:aa02-ucshost:2"
    nvme_nqn: "nqn.2014-08.com.cisco.flexpodb4:nvme:aa02-esxi-2"
  - hostname: "aa02-esxi-4"
    iscsi_iqn: "iqn.2010-11.com.flexpod:aa02-ucshost:1"
    nvme_nqn: "nqn.2014-08.com.cisco.flexpodb4:nvme:aa02-esxi-4"
  - hostname: "aa02-esxi-6"
    iscsi_iqn: "iqn.2010-11.com.flexpod:aa02-ucshost:3"
    nvme_nqn: "nqn.2014-08.com.cisco.flexpodb4:nvme:aa02-esxi-6"

# Storage SAN Identifiers
#
# Storage FCP WWPNs (capture from storage system)
#
fcp_lif_01a: '20:01:00:a0:98:e2:17:ca'
fcp_lif_02a: '20:03:00:a0:98:e2:17:ca'
fcp_lif_01b: '20:02:00:a0:98:e2:17:ca'
fcp_lif_02b: '20:04:00:a0:98:e2:17:ca'
#
# Storage FC-NVMe WWPNs (capture from storage system)
#
fc_nvme_lif_01a: '20:06:00:a0:98:e2:17:ca'
fc_nvme_lif_02a: '20:08:00:a0:98:e2:17:ca'
fc_nvme_lif_01b: '20:07:00:a0:98:e2:17:ca'
fc_nvme_lif_02b: '20:09:00:a0:98:e2:17:ca'
#
# Storage iSCSI Target Interfaces
#
iscsi_lif_01a: '192.168.10.31'
iscsi_lif_01b: '192.168.20.31'
iscsi_lif_02a: '192.168.10.32'
iscsi_lif_02b: '192.168.20.32'
#
# Storage NFS Target Interfaces
#
nfs_lif_01: '192.168.3.103'
nfs_lif_02: '192.168.3.104'
#
# Storage iSCSI Target IQN
#
storage_iscsi_IQN: 'iqn.1992-08.com.netapp:sn.c4f9c442816c11edb42400a098e217cb:vs.3'
#
#############################################################################################################################
#
# NetApp Storage Virtual Machine informantion for this Tenant
#
cluster          : 'c250-02'                   # NetApp cluster name, also used as ansible_host in inventory !!!
aggr_prefix      : 'c250_02'                   # Should be same as cluster name

svm_specs:
  svm_name: "{{ tenant_name }}_svm"
  svm_root_vol: "{{ tenant_name }}_svm_root"
  allowed_protocols:
    #provide the values in lower case only, supported options for this solution are nfs, fcp, iscsi, nvme
    #For FC-NVMe config, use fcp and nvme
    #For NVMe/TCP config, use nvme and iscsi
    - nfs
#    - fcp  
#    - nvme
    - iscsi
  data_protocol: nfs
  client_match: "{{ t_nfs_network_prefix }}.0/{{ t_nfs_network_mask }}"
  data_volumes_file: # If name includes swap - volume efficientcy will be disabled
    - {name: "{{tenant_name}}_datastore", size: 1024, residing_aggr: "{{ aggr_prefix }}n2_aggr1"}
    - {name: "{{tenant_name}}_swap", size: 1024, residing_aggr: "{{ aggr_prefix }}n1_aggr1"}
    - {name: "{{tenant_name}}_vCLS", size: 100, residing_aggr: "{{ aggr_prefix }}n2_aggr1"}
  data_volumes_block:
    - {name: "{{tenant_name}}_boot", size: 1024, residing_aggr: "{{ aggr_prefix }}n1_aggr1"}
      #    - {name: "{{tenant_name}}_nvme", size: 1024, residing_aggr: c250_02n2_aggr1}
  nvme_subsystem: nvme_infra_hosts
    #  nvme_namespaces:  #Mention the namespaces that you want to create and map to the subsystem
    #    - {name: "{{tenant_name}}_nvme_01", size: 500, residing_vol: "{{tenant_name}}_nvme"}
  #host names will be used for NetApp Boot LUNs and igroup names. These vars are placed under group_vars/all.yml file
  boot_luns_iscsi: {size: 128, residing_vol: "{{tenant_name}}_boot"}
  svm_mgmt_lif: {home_node: "{{ cluster }}n2", address: "{{ t_ib_network_prefix }}.101", netmask: 255.255.255.0, gateway: "{{ t_ib_network_prefix }}.1", lif_name: "{{ tenant_name }}-svm-mgmt"}
  vsadmin_password: GpuSystem24!
  os_type: linux
  dns_server_svm:
    - "{{ dns_servers[0].ip_address }}"
      #    - "{{ dns_servers[1].ip_address }}"
  dns_domain_svm: "{{ dns_domain_name }}"
  svm_login_banner: This SVM is reserved for authorized users only!  #SVM Login banner Text message
  audit_log_volume_specs: {name: "{{tenant_name}}_audit_log", size: 50, residing_aggr: c250_01n1_aggr1}  #Audit log destination volume where consolidated audit logs will be stored

svm_node_specs:
  - node_name: "{{ cluster }}n1"
    nfs_lifs:  {name: "{{ tenant_name }}-nfs-lif-01a", address: "{{ nfs_lif_01 }}", netmask: 255.255.255.0}
    fcp_lifs:    #Fill out this value only if fcp will be mentioned under allowed_protocols in svm_specs
      - {name: "{{ tenant_name }}-fcp-lif-01a", home_port: 5a, fabric: A}  #Do not change the fabric ID
      - {name: "{{ tenant_name }}-fcp-lif-01b", home_port: 5b, fabric: B}  #Do not change the fabric ID
    fc-nvme_lifs:    #Fill out this value only if fcp and nvme will be mentioned under allowed_protocols in svm_specs
      - {name: "{{ tenant_name }}-fc-nvme-lif-01a", home_port: 2a, fabric: A}  #Do not change the fabric ID
      - {name: "{{ tenant_name }}-fc-nvme-lif-01b", home_port: 2b, fabric: B}  #Do not change the fabric ID
    iscsi_lifs:  #Fill out this value only if iscsi will be mentioned under allowed_protocols in svm_specs. 
      - {name: "{{ tenant_name }}-iscsi-lif-01a", address: "{{ iscsi_lif_01a }}", netmask: 255.255.255.0, fabric: A}  #Do not change the fabric ID
      - {name: "{{ tenant_name }}-iscsi-lif-01b", address: "{{ iscsi_lif_01b }}", netmask: 255.255.255.0, fabric: B}  #Do not change the fabric ID
    nvme_tcp_lifs:  #Fill out this value only if iscsi and nvme will be mentioned under allowed_protocols 
      - {name: "{{ tenant_name }}-nvme-tcp-lif-01a", address: "{{ nvme_lif_01a }}", netmask: 255.255.255.0, fabric: A}  #Don't change fabric ID
      - {name: "{{ tenant_name }}-nvme-tcp-lif-01b", address: "{{ nvme_lif_01b }}", netmask: 255.255.255.0, fabric: B}  #Don't change fabric ID
  - node_name: "{{ cluster }}n2"
    nfs_lifs:  {name: "{{ tenant_name }}-nfs-lif-02b", address: "{{ nfs_lif_02 }}", netmask: 255.255.255.0}
    fcp_lifs:    #Fill out this value only if fcp will be mentioned under allowed_protocols in svm_specs
      - {name: "{{ tenant_name }}-fcp-lif-02a", home_port: 5a, fabric: A}  #Do not change the fabric ID
      - {name: "{{ tenant_name }}-fcp-lif-02b", home_port: 5b, fabric: B}  #Do not change the fabric ID
    fc-nvme_lifs:    #Fill out this value only if fcp and nvme will be mentioned under allowed_protocols 
      - {name: "{{ tenant_name }}-fc-nvme-lif-02a", home_port: 2a, fabric: A}  #Do not change the fabric ID
      - {name: "{{ tenant_name }}-fc-nvme-lif-02b", home_port: 2b, fabric: B}  #Do not change the fabric ID
    iscsi_lifs:  #Fill out this value only if iscsi will be mentioned under allowed_protocols in svm_specs. 
      - {name: "{{ tenant_name }}-iscsi-lif-02a", address: "{{ iscsi_lif_02a }}", netmask: 255.255.255.0, fabric: A}  #Do not change the fabric ID
      - {name: "{{ tenant_name }}-iscsi-lif-02b", address: "{{ iscsi_lif_02b }}", netmask: 255.255.255.0, fabric: B}  #Do not change the fabric ID
    nvme_tcp_lifs:  #Fill out this value only if iscsi and nvme will be mentioned under allowed_protocols 
      - {name: "{{ tenant_name }}-nvme-tcp-lif-02a", address: "{{ nvme_lif_02a }}", netmask: 255.255.255.0, fabric: A}  #Don't change fabric ID
      - {name: "{{ tenant_name }}-nvme-tcp-lif-02b", address: "{{ nvme_lif_02b }}", netmask: 255.255.255.0, fabric: B}  #Don't change fabric ID


#############################################################################################################################
# This is the list of all the VLANs that will be defined on Nexus, Storage, UCS, and VMware
# VLAN Names are adjustable and can be modified in here
# Comment out any VLANs that are not used here and below (iSCSI and NVMe-TCP)
#
## t_XXXX_name          : Defines the Name of the network
# t_XXXX_id            : Defines the VLAN ID of the network
# t_XXXX_network_prefix: Defines the first three digits of the network ip address.
#                        Host IPs, Storage IPs, and Routing IPs are automaticaliy added to the prefix
#                        Router IP is set as default to .1
#                        SVI IP on n9kA is .2 and on n9kB is .2
#                        NetApp SVM IPs are set to .101 o node 1 and .102 on node 2.
# t_XXXX_network_mask  : Defines the netmask of the network
#
t_ib_vlan_name:           "{{ tenant_name }}-Management_LAN"   # IN BAND Management VLAN
t_ib_vlan_id:             300                                  # VLAN ID for IN-BAND Management
t_ib_network_prefix:      '172.18.0.'                          # first three digits of the network adress
t_ib_network_mask:        24                                   # Netmask
#
t_iscsiA_vlan_name:       "{{ tenant_name }}-iSCSI-A"          # iSCSI-A VLAN (if needed)
t_iscsiA_vlan_id:         "{{ t_ib_vlan_id + 1 }}"             # Management VLAN +1
t_iscsiA_network_prefix:  '172.18.1'                           # first three digits of the network adress
t_iscsiA_network_mask:    24                                   # Netmask
#
t_iscsiB_vlan_name:       "{{ tenant_name }}-iSCSI-B"          # iSCSI-B VLAN (if needed)
t_iscsiB_vlan_id:         "{{ t_ib_vlan_id + 2 }}"             # Management VLAN +2
t_iscsiB_network_prefix:  '172.18.2'                           # first three digits of the network adress
t_iscsiB_network_mask:    24                                   # Netmask
#
t_nfs_vlan_name:          "{{ tenant_name }}-NFS"              # NFS Traffic between ESXi and Storage
t_nfs_vlan_id:            "{{ t_ib_vlan_id + 3 }}"             # Management VLAN +3
t_nfs_network_prefix:     '172.18.3'                           # first three digits of the network adress
t_nfs_network_mask:       24                                   # Netmask
#
t_access_vlan_name:       "{{ tenant_name }}-Access-Traffic"   # VLAN to carry Access traffic to RKE2 payload
t_access_vlan_id:         "{{ t_ib_vlan_id + 4 }}"             # Management VLAN +4
t_access_network_prefix:  '172.18.4'                           # first three digits of the network adress
t_access_network_mask:    24                                   # Netmask
#
t_vm_vlan_name:           "{{ tenant_name }}-VM-Traffic"       # VLAN to carry VM traffic on VDS
t_vm_vlan_id:             "{{ t_ib_vlan_id + 5 }}"             # Management VLAN +5
t_vm_network_prefix:      '172.18.5'                           # first three digits of the network adress
t_vm_network_mask:        24                                   # Netmask
#
t_vmotion_vlan_name:      "{{ tenant_name }}-vMotion"          # vMotion VLAN
t_vmotion_vlan_id:        "{{ t_ib_vlan_id + 6 }}"             # Management VLAN +6
t_vmotion_network_prefix: '172.18.6'                           # first three digits of the network adress
t_vmotion_network_mask:   24                                   # Netmask
#
t_nvme_tcpA_vlan_name:    "{{ tenant_name }}-Infra-NVMe-TCP-A" # NVMe-TCP-A VLAN (if needed)
t_nvme_tcpA_vlan_id:      "{{ t_ib_vlan_id + 7 }}"             # Management VLAN +7
t_nvme_tcpA_network_prefix: '172.18.7'                         # first three digits of the network adress
t_nvme_tcpB_network_mask: 24                                   # Netmask
#
t_nvme_tcpB_vlan_name:    "{{ tenant_name }}-Infra-NVMe-TCP-B" # NVMe-TCP-B VLAN (if needed)
t_nvme_tcpB_vlan_id:      "{{ t_ib_vlan_id + 8 }}"             # Management VLAN +8
t_nvme_tcpB_network_prefix: '172.18.8'                         # first three digits of the network adress
t_nvme_tcpB_network_mask: 24                                   # Netmask
#
#
# lan_state should be set to 'present' to configure the objects
# In future, this parameter will be used for deleting the configuration
#
lan_state : 'present'
#
# VLAN Lists - Comment out or remove any VLANs not being used.
#
# The ib_mgmt_vlan_list contains one entry, the IB-MGMT VLAN.
#
t_ib_mgmt_vlan_list:
  - name: "{{ t_ib_vlan_name }}"
    id: "{{ t_ib_vlan_id }}"
    native: 'no'
    state: "{{lan_state}}"
#
# The storage_vlan_list contains VLANs that are configured on the storage controllers.
# These VLANs are also configured in the UCS and in the Nexus switches. This list has
# two extra fields, storage_protocol, and fabric. Do not remove these extra fields.
#
t_storage_vlan_list:
  - name: "{{ t_nfs_vlan_name }}"
    id: "{{ t_nfs_vlan_id }}"
    native: 'no'
    storage_protocol: NFS
    state: "{{lan_state}}"
    # ISCSI A and B VLANs should be deleted or commended out for Fiber-Channel-Only deployments
  - name: "{{ t_iscsiA_vlan_name }}"
    id: "{{ t_iscsiA_vlan_id }}"
    native: 'no'
    storage_protocol: iSCSI
    fabric: A
    state: "{{lan_state}}"
  - name: "{{ t_iscsiB_vlan_name }}"
    id: "{{ t_iscsiB_vlan_id }}"
    native: 'no'
    storage_protocol: iSCSI
    fabric: B
    state: "{{lan_state}}"
  - name: "{{ t_nvme_tcpA_vlan_name }}"
    id: "{{ t_nvme_tcpA_vlan_id }}"
    native: 'no'
    storage_protocol: NVMe
    fabric: A
    state: "{{lan_state}}"
  - name: "{{ t_nvme_tcpB_vlan_name }}"
    id: "{{ t_nvme_tcpB_vlan_id }}"
    native: 'no'
    storage_protocol: NVMe
    fabric: B
    state: "{{lan_state}}"

# The remaining_vlan_list contains all vlans that are not configured on storage,
# but are configured in Nexus and UCS.
#
t_remaining_vlan_list:
  - name: "{{ t_vm_vlan_name }}"
    id: "{{ t_vm_vlan_id }}"
    native: 'no'
    state: "{{lan_state}}"
  - name: "{{ t_vmotion_vlan_name }}"
    id: "{{ t_vmotion_vlan_id }}"
    native: 'no'
    state: "{{lan_state}}"

# VLANs definitions below will be used to setup trunk ports on Nexus Switches
# all_vlans_list: for vpc_peer_link and UCS FI trunk ports
# These VLANs must be same or a subset of the vlan_list abovea
# Comment out or remove any VLANs that are not used (iSCSI and NVMe-TCP)
# In future, these values will be auto-generated
#
t_all_vlans_list: "{{ oob_vlan_id }},{{ t_ib_vlan_id }},{{ t_vm_vlan_id }},{{ t_nfs_vlan_id }},{{ t_vmotion_vlan_id }},{{ t_iscsiA_vlan_id }},{{ t_iscsiB_vlan_id }},{{ t_nvme_tcpA_vlan_id }},{{ t_nvme_tcpB_vlan_id }}"
# storage_vlans_list: for storage uplink trunk ports
t_storage_vlans_list: "{{ t_ib_vlan_id }},{{ t_nfs_vlan_id }},{{ t_iscsiA_vlan_id }},{{ t_iscsiB_vlan_id }},{{ t_nvme_tcpA_vlan_id }},{{ t_nvme_tcpB_vlan_id }}"
# mgmt_vlans_list: for uplink/management switch trunk port
t_mgmt_vlans_list: "{{ oob_vlan_id }},{{ t_ib_vlan_id }},{{ t_vm_vlan_id }}"
#
#
# The SVI list defines IP and VRF information to enable routing function on the Nexus Switches.
# The baseIP is defined in the nexus host configuration file in the hosts_var directory.
# 
t_svi_list:
  - name:  "{{ t_ib_vlan_id }}"
    vrf: "vmware"
    address: "{{ t_ib_network_prefix}}.{{ baseIP }}/{{ t_ib_network_mask }}"
    hsrp: "{{ t_ib_network_prefix}}.1"
  - name:  "{{ t_iscsiA_vlan_id }}"
    vrf: "vmware"
    address: "{{ t_iscsiA_network_prefix }}.{{ baseIP }}/{{ t_iscsiA_network_mask }}"
    hsrp: "{{ t_iscsiA_network_prefix }}.1"
  - name:  "{{ t_iscsiB_vlan_id }}"
    vrf: "vmware"
    address: "{{ t_iscsiB_network_prefix }}.{{ baseIP }}/{{ t_iscsiB_network_mask }}"
    hsrp: "{{ t_iscsiB_network_prefix }}.1"
  - name:  "{{ t_nfs_vlan_id }}"
    vrf: "vmware"
    address: "{{ t_nfs_network_prefix }}.{{ baseIP }}/{{ t_nfs_network_mask }}"
    hsrp: "{{ t_nfs_network_prefix }}.1"
  - name:  "{{ t_access_vlan_id }}"
    vrf: "vmware"
    address: "{{ t_access_network_prefix }}.{{ baseIP }}/{{ t_access_network_mask }}"
    hsrp: "{{ t_access_network_prefix }}.1"

# VLAN/Portgroup List with Pinning info for VMware Distributed Switch vDSO for vMotion and Tenant Data/Storage
vds0_vlan_list:
  - name: "{{ t_vm_vlan_name }}"
    # portgroup name will be configured in VMware
    portgroup_name: "{{ t_vm_vlan_name }}"
    id: "{{ t_vm_vlan_id }}"
    active_uplinks: 
      - "Uplink 1"
      - "Uplink 2"
    standby_uplinks: []
  - name: "{{ t_vmotion_vlan_name }}"
    # portgroup name will be configured in VMware
    portgroup_name: "{{ t_vmotion_vlan_name }}"
    id: "{{ t_vmotion_vlan_id }}"
    active_uplinks: "Uplink 2"
    standby_uplinks: "Uplink 1"
#
# VLAN/Portgroup List with Pinning info for VMware Distributed Switch iSCSI-NVMe-TCP-vDS for iSCSI and NVMe Storage
iscsi_nvme_tcp_vds_vlan_list:
  - name: "{{ t_iscsiA_vlan_name }}"
    # portgroup name will be configured in VMware
    portgroup_name: "{{ t_iscsiA_vlan_name }}"
    id: '0'  # iSCSI VLAN A is set as native for this vNIC
    active_uplinks:
      - "Uplink 1"
    standby_uplinks: []
  - name: "{{ t_iscsiB_vlan_name }}"
    # portgroup name will be configured in VMware
    portgroup_name: "{{ t_iscsiB_vlan_name }}"
    id: '0'  # iSCSI VLAN B is set as native for this vNIC
    active_uplinks:
      - "Uplink 2"
    standby_uplinks: []
  - name: "{{ t_nvme_tcpA_vlan_name }}"
    # portgroup name will be configured in VMware
    portgroup_name: "{{ t_nvme_tcpA_vlan_name }}"
    id: "{{ t_nvme_tcpA_vlan_id }}"
    active_uplinks:
      - "Uplink 1"
    standby_uplinks: []
  - name: "{{ t_nvme_tcpB_vlan_name }}"
    # portgroup name will be configured in VMware
    portgroup_name: "{{ t_nvme_tcpB_vlan_name }}"
    id: "{{ t_nvme_tcpB_vlan_id }}"
    active_uplinks:
      - "Uplink 2"
    standby_uplinks: []

nfs_portgroup: "VMKernel-Infra-NFS"
esxi_nfs_vlan: "{{ t_nfs_vlan_id }}"
#
oob_mgmt_portgroup: "OOB-MGMT Network"
oob_mgmt_vlan: "{{ oob_vlan_id }}"
#
#VSAN Parameters
#
t_vsan_A_name: 'FlexPod-Fabric-A'
t_vsan_A_id: 101
t_vsan_A_fcoe_vlan: 101
#
t_vsan_B_name: 'FlexPod-Fabric-B'
t_vsan_B_id: 102
t_vsan_B_fcoe_vlan: 102
#
# VMware Configurations
# provide the user names and passwords to connect to the ESXi servers
# and VMware vCenter
#
esxi_username: root
esxi_password: "{{ ansible_ssh_pass }}"
#
vcenter_dc: FlexPod-DC
vcenter_cluster: FlexPod-Management
#
vcenter_hostname: "10.102.1.100"
# e.g. vcenter_hostname: 10.50.160.100
vcenter_username: "administrator@vsphere.local"
# e.g. vcenter_username: administrator@vsphere.local
vcenter_password: "<password>"
# e.g. vcenter_password: "cisco!23"
#
# DVS Parameters; use version 7.0.3 for VMware 7.0U3 or above
#
dvs_name: "vDS0"
iscsi_nvme_tcp_dvs_name: "iSCSI-NVMe-TCP-vDS" # Change to "iSCSI-vDS" if not using NVMe-TCP
dv_version: "7.0.3"
dv_uplink: "2"
dv_protocol: "lldp"
dv_operation: "both"
